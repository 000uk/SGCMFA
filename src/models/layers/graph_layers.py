import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

class Graph:
    def __init__(self, strategy='uniform'):
        self.num_node = 21
        self.edges = self.get_edges()
        self.A = self.get_adjacency_matrix(self.edges, self.num_node)

    def get_edges(self):
        # MediaPipe Hands 기준 연결 정보
        # 0:손목, 1-4:엄지, 5-8:검지, ...
        self_link = [(i, i) for i in range(self.num_node)]
        neighbor_link = [
            (0, 1), (1, 2), (2, 3), (3, 4),      # Thumb
            (0, 5), (5, 6), (6, 7), (7, 8),      # Index
            (0, 9), (9, 10), (10, 11), (11, 12), # Middle
            (0, 13), (13, 14), (14, 15), (15, 16), # Ring
            (0, 17), (17, 18), (18, 19), (19, 20)  # Pinky
        ]
        return self_link + neighbor_link

    def get_adjacency_matrix(self, edges, num_node):
        A = np.zeros((num_node, num_node))
        for i, j in edges:
            A[j, i] = 1
            A[i, j] = 1
        DL = np.sum(A, 0)
        Dn = np.zeros((num_node, num_node))
        for i in range(num_node):
            if DL[i] > 0:
                Dn[i, i] = DL[i]**(-0.5)
        DAD = np.dot(np.dot(Dn, A), Dn)
        return torch.tensor(DAD, dtype=torch.float32)

class GraphConv(nn.Module):
    def __init__(self, in_channels, out_channels, A):
        super(GraphConv, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)
        self.A = nn.Parameter(A, requires_grad=False)
        # Adaptive Graph (선택사항: 성능 더 올리고 싶으면 주석 해제)
        # self.PA = nn.Parameter(torch.zeros_like(A), requires_grad=True)

    def forward(self, x):
        x = self.conv(x)
        n, c, t, v = x.size()
        x = x.view(n, c * t, v)
        # x = torch.matmul(x, self.A + self.PA) # Adaptive 사용 시
        x = torch.matmul(x, self.A) 
        x = x.view(n, c, t, v)
        return x
    
class ST_GCN_Block(nn.Module):
    def __init__(self, in_channels, out_channels, A, stride=1):
        super(ST_GCN_Block, self).__init__()

        # Spatial Graph Conv
        self.gcn = GraphConv(in_channels, out_channels, A)

        # Temporal Conv (시간축으로 1D Conv)
        # kernel_size=(9, 1): 시간축으로 9프레임을 봄
        self.tcn = nn.Sequential(
            nn.BatchNorm2d(out_channels),
            nn.ReLU(),
            nn.Conv2d(
                out_channels,
                out_channels,
                (9, 1), # (Time, Node) -> Node는 섞지 않고 시간만 봄
                padding=(4, 0),
                stride=(stride, 1)
            ),
            nn.BatchNorm2d(out_channels),
            nn.Dropout(0.5, inplace=True) # 과적합 방지
        )
        
        # Coordinate Attention 적용 (Spatial)
        self.attention = CoordAtt(out_channels) 

        # Residual Connection (ResNet처럼 입력 더하기)
        if in_channels != out_channels or stride != 1:
            self.residual = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=(stride, 1)),
                nn.BatchNorm2d(out_channels),
            )
        else:
            self.residual = nn.Identity()

    def forward(self, x):
        res = self.residual(x)
        x = self.gcn(x) # 공간
        x = self.tcn(x) # 시간
        x = self.attention(x) # Attention
        return F.relu(x + res)

class CoordAtt(nn.Module):
    def __init__(self, inp, reduction=32):
        super(CoordAtt, self).__init__()
        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))
        self.pool_w = nn.AdaptiveAvgPool2d((1, None))

        mip = max(8, inp // reduction)
        self.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0)
        self.bn1 = nn.BatchNorm2d(mip)
        self.act = nn.Hardswish()
        
        self.conv_h = nn.Conv2d(mip, inp, kernel_size=1, stride=1, padding=0)
        self.conv_w = nn.Conv2d(mip, inp, kernel_size=1, stride=1, padding=0)

    def forward(self, x):
        n, c, t, v = x.size()
        x_h = self.pool_h(x)
        x_w = self.pool_w(x).permute(0, 1, 3, 2)

        y = torch.cat([x_h, x_w], dim=2)
        y = self.act(self.bn1(self.conv1(y)))
        
        x_h, x_w = torch.split(y, [t, v], dim=2)
        x_w = x_w.permute(0, 1, 3, 2)

        a_h = self.conv_h(x_h).sigmoid()
        a_w = self.conv_w(x_w).sigmoid()
        return x * a_h * a_w
    
class TemporalAttention(nn.Module):
    def __init__(self, channel, t_dim=30): # t_dim: 사용하는 프레임 수
        super(TemporalAttention, self).__init__()
        # (N, C, T, V) -> (N, 1, T, 1) : 시간 축만 살리고 다 압축
        self.avg_pool = nn.AdaptiveAvgPool2d((t_dim, 1))

        # 각 프레임의 중요도를 0~1 사이 점수로 매김
        self.fc = nn.Sequential(
            nn.Conv2d(channel, channel // 8, kernel_size=1, bias=False),
            nn.ReLU(),
            nn.Conv2d(channel // 8, 1, kernel_size=1, bias=False), # 채널을 1개로 (점수판)
            nn.Sigmoid()
        )

    def forward(self, x):
        # x: (N, C, T, V)
        b, c, t, v = x.size()

        # 1. 전체 노드에 대해 평균을 내서 "이 시간대의 대표 값"을 뽑음
        y = F.avg_pool2d(x, (1, v)) # (N, C, T, 1)

        # 2. 어떤 시간이 중요한지 점수 계산
        score = self.fc(y) # (N, 1, T, 1) - 각 프레임 별 점수 (0~1)

        # 3. 중요도 곱하기 (중요한 프레임은 살리고, 잡음 프레임은 죽임)
        return x * score